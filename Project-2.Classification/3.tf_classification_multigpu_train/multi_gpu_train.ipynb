{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3811311e3b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mvalid_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data/minjun/Auged_datasets/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/valid_3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_images_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3811311e3b24>\u001b[0m in \u001b[0;36mbasic_processing\u001b[0;34m(ds_path, is_training)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "def basic_processing(ds_path, is_training):\n",
    "    ds_path = pathlib.Path(ds_path)\n",
    "\n",
    "    images = list(ds_path.glob('*/*'))\n",
    "    images = [str(path) for path in images]\n",
    "    len_images = len(images)\n",
    "\n",
    "    if is_training:\n",
    "        random.shuffle(images)\n",
    "\n",
    "    labels = sorted(item.name for item in ds_path.glob('*/') if item.is_dir())\n",
    "    labels_len = len(labels)\n",
    "    labels = dict((name, index) for index, name in enumerate(labels))\n",
    "    labels = [labels[pathlib.Path(path).parent.name] for path in images]\n",
    "    labels = tf.keras.utils.to_categorical(labels, num_classes=labels_len, dtype='float32')\n",
    "\n",
    "    return images, labels, len_images, labels_len\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    \n",
    "    return preprocess_image(image)\n",
    "\n",
    "\n",
    "def make_tf_dataset(images, labels):\n",
    "    image_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "    image_ds = image_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    lable_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.float32))\n",
    "\n",
    "    image_label_ds = tf.data.Dataset.zip((image_ds, lable_ds))\n",
    "\n",
    "    return image_label_ds\n",
    "\n",
    "\n",
    "def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n",
    "               lr_min=0.00001, lr_rampup_epochs=5, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) *\\\n",
    "                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n",
    "                                - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    return lrfn\n",
    "\n",
    "\n",
    "# def build_model():\n",
    "#     base_model = tf.keras.applications.EfficientNetB5(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "#                                 weights=\"imagenet\", # noisy-student\n",
    "#                                 include_top=False)\n",
    "#     avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "#     output = tf.keras.layers.Dense(train_labels_len, activation=\"softmax\")(avg)\n",
    "#     model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = True\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10000)])\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    print(e)\n",
    "\n",
    "\n",
    "model_name = \"EfficientNet-B5\"\n",
    "dataset_name = 'd_beverage'\n",
    "train_dataset_path = '/data/minjun/Auged_datasets/' + dataset_name + '/train_3'\n",
    "valid_dataset_path = '/data/minjun/Auged_datasets/' + dataset_name + '/valid_3'\n",
    "\n",
    "train_images, train_labels, train_images_len, train_labels_len = basic_processing(train_dataset_path, True)\n",
    "valid_images, valid_labels, valid_images_len, valid_labels_len = basic_processing(valid_dataset_path, False)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 4 * strategy.num_replicas_in_sync\n",
    "IMG_SIZE = 224\n",
    "NUM_EPOCHS = 30\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "TRAIN_STEP_PER_EPOCH = int(train_images_len / BATCH_SIZE)\n",
    "VALID_STEP_PER_EPOCH = int(valid_images_len / BATCH_SIZE)\n",
    "\n",
    "saved_path = './model/'\n",
    "time = datetime.datetime.now().strftime(\"%Y.%m.%d_%H:%M\") + '_tf2'\n",
    "weight_file_name = '{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "if not(os.path.isdir(saved_path + dataset_name + '/' + time)):\n",
    "    os.makedirs(os.path.join(saved_path + dataset_name + '/' + time))\n",
    "\n",
    "    f = open(saved_path + dataset_name + '/' + time + '/README.txt', 'w')\n",
    "    f.write('IMG_SIZE = ' + str(IMG_SIZE) + '\\n')\n",
    "    f.write(train_dataset_path + '\\n')\n",
    "    f.write(valid_dataset_path + '\\n')\n",
    "    f.write(\"Model : \" + model_name)\n",
    "    f.close()\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "train_ds = make_tf_dataset(train_images, train_labels)\n",
    "valid_ds = make_tf_dataset(valid_images, valid_labels)\n",
    "\n",
    "train_ds = train_ds.repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "valid_ds = valid_ds.repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.applications.EfficientNetB5(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                                                      weights=\"imagenet\", # noisy-student\n",
    "                                                      include_top=False)\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    output = tf.keras.layers.Dense(train_labels_len, activation=\"softmax\")(avg)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cb_early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint_path = saved_path + dataset_name + '/' + time + '/' + weight_file_name\n",
    "cb_checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                    monitor='val_accuracy',\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='max')\n",
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)    \n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    steps_per_epoch=TRAIN_STEP_PER_EPOCH,\n",
    "                    shuffle=False,\n",
    "                    validation_data=valid_ds,\n",
    "                    validation_steps=VALID_STEP_PER_EPOCH,\n",
    "                    verbose=1,\n",
    "                    workers=1,\n",
    "                    callbacks=[cb_early_stopper, cb_checkpointer, lr_schedule])\n",
    "                    # callbacks=[cb_early_stopper, lr_schedule])\n",
    "\n",
    "model.save(saved_path + dataset_name + '/' + time + '/' + dataset_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bitfc54d0e8d1c64783b4b1eeb9034183ec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
